{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyONwzGZHD5GbQjl/4s6XgeM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/insoucyant/Learn_Python/blob/master/TorchBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is a deep learning framework and scientific computing package. The scientific computing aspect of PyTorch is primarily a result of PyTroch's tensor libraray and associated Tensor operations."
      ],
      "metadata": {
        "id": "-muecqW3XWyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch\n",
        "Torch is the core library and namespace that provide the fundamental building blocks for deep learning.  \n",
        "torch is the low level foundation upon which the higher level components of PyTorch, such as torch.nn (for neural network layers) and torch.optim (for optimizers), are built\n",
        "The main torch libraries/subpackages are:\n",
        "* *torch.nn* : &emsp; This subpackage provides modules for building neural network including\n",
        "  * layers: &emsp; e.g., Linear, Conv2d\n",
        "  * activation functions: &emsp; e.g., ReLU, Sigmoid\n",
        "  * loss functions: &emsp; e.g., MSELoss, CrossEntropyLoss\n",
        "  * Containers for combining Layers: &emsp; e.g., Sequential, ModuleList\n",
        "* *torch.autograd* : &emsp; This package is the core of PyTorch's **Automatic Differentiation Engine**, whicg automatically computes gradients for all operations on tensors as well as for backpropagation.\n",
        "* *torch.nn.functional* : &emsp; A functional interface that offers many of the same operations as *torch.nn* (like activations and convolutions) but in a functional, stateless form. These are often used when you don'y need to manage parameters within your module.\n",
        "* *torch.optim* : &emsp; This subpackage offers various optimization algorithms used to train neural networks, such as\n",
        "  * SGD,\n",
        "  * Adam,\n",
        "  * RMSprop, and\n",
        "  * Adagrad.\n",
        "\n",
        "* *torch.utils* : &emsp; Provides utility classes and functions for tasks like data handling and multiprocessing.\n",
        "* *torch.utils.data* : &emsp; This subpackage provides utilities for working with datasets and data loading, including Dataset for representing data samples and DataLoader for efficiently loading data in batches.\n",
        "* *torchvision* : &emsp; This is a separate library that provides access to popular datasets (MNIST, CIFAR-10), model architectures (ResNet, VGG) and image transformations specifically for computer vision tasks. It includes pre trained models in *torchvision.models* and common datasets in *torchvision.datasets*\n",
        "* *torchaudio* : &emsp; This is another separate library focused on audio processing. It offers datasets, model architectures, and transformations relevant to audio tasks like speech recognition and audio classification.\n",
        "* *torchtext* : &emsp; The libraray is designed for natural language processing (NLP) tasks. It provides datasets, text processing utilities, and model architectures common in NLP, such as recurrent neural networks and transformers.\n",
        "* *torch.cuda* : &emsp; This package provides functionalities for interacting with Nvidia GPUs, enabling computation to be performed on the GPU for faster training and inference.\n",
        "* *torch.multiprocessing* : A wrapper for the multiprocessing module that handles sharing CUDA tensors between processes."
      ],
      "metadata": {
        "id": "JGibYhKdZjcV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3wxYfFeCCFK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fT6znD54CDXj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8s54kEqF5mO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VFsPXrFn0vvO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qHe8MRQ01CH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "syG6bav54_EE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZM4PiioKXNf5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FhvEAt9Yiqyi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TgC0u5LSjKRS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gy6TY_w95dgw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BHxjnjBD6c71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ai-B-V7q7-oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7k5QQaX6N81"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NZJR3JDf8wnU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MaG42Eb18Hmy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6g7CHYFSa8wq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MDGQn2vga84u"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OjjlbM9-a9C2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RFANhpM4a_TH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}